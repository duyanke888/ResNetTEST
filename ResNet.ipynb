{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random\n",
    "# 引入Tensorboard\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSet():\n",
    "    \n",
    "    train_path_ZAZXCMAB ='./mynn/train/ZAZXCMAB/'\n",
    "    train_path_ZUXJZPMFB = './mynn/train/ZUXJZPMFB/'\n",
    "    train_path_ZUXTSFB = './mynn/train/ZUXTSFB/'\n",
    "    train_path_ZUXWXSYFB = './mynn/train/ZUXWXSYFB/'\n",
    "    train_path_ZUXZYFB = './mynn/train/ZUXZYFB/'\n",
    "    train_path_ZXJXFB = './mynn/train/ZXJXFB/'\n",
    "    \n",
    "    test_path_ZAZXCMAB ='./mynn/test/ZAZXCMAB/'\n",
    "    test_path_ZUXJZPMFB = './mynn/test/ZUXJZPMFB/'\n",
    "    test_path_ZUXTSFB = './mynn/test/ZUXTSFB/'\n",
    "    test_path_ZUXWXSYFB = './mynn/test/ZUXWXSYFB/'\n",
    "    test_path_ZUXZYFB = './mynn/test/ZUXZYFB/'\n",
    "    test_path_ZXJXFB = './mynn/test/ZXJXFB/'\n",
    "    \n",
    "    imglist_train_ZAZXCMAB = os.listdir(train_path_ZAZXCMAB)\n",
    "    imglist_train_ZUXJZPMFB = os.listdir(train_path_ZUXJZPMFB)\n",
    "    imglist_train_ZUXTSFB = os.listdir(train_path_ZUXTSFB)\n",
    "    imglist_train_ZUXWXSYFB = os.listdir(train_path_ZUXWXSYFB)\n",
    "    imglist_train_ZUXZYFB = os.listdir(train_path_ZUXZYFB)\n",
    "    imglist_train_ZXJXFB = os.listdir(train_path_ZXJXFB)\n",
    "    \n",
    "    imglist_test_ZAZXCMAB = os.listdir(test_path_ZAZXCMAB)\n",
    "    imglist_test_ZUXJZPMFB = os.listdir(test_path_ZUXJZPMFB)\n",
    "    imglist_test_ZUXTSFB = os.listdir(test_path_ZUXTSFB)\n",
    "    imglist_test_ZUXWXSYFB = os.listdir(test_path_ZUXWXSYFB)\n",
    "    imglist_test_ZUXZYFB = os.listdir(test_path_ZUXZYFB)\n",
    "    imglist_test_ZXJXFB = os.listdir(test_path_ZXJXFB)\n",
    "    \n",
    "    # 这里定义两个 numpy 对象，X_train 和 Y_train\n",
    "    \n",
    "    # X_train 对象用来存放训练集的图片。每张图片都需要转换成 numpy 向量形式\n",
    "    # X_train 的 shape 是 (360，224，224，3) \n",
    "    # 360 是训练集中图片的数量\n",
    "    # 因为 resnet 要求输入的图片尺寸是 (224,224) , 所以要设置成相同大小（也可以设置成其它大小，参看 keras 的文档）\n",
    "    # 3 是图片的通道数（rgb）\n",
    "    \n",
    "    # Y_train 用来存放训练集中每张图片对应的标签\n",
    "    # Y_train 的 shape 是 （360，2）\n",
    "    # 360 是训练集中图片的数量（训练集中固体胶和西瓜霜图片数量之和）\n",
    "    # 因为一共有两种图片，所以第二个维度设置为 2\n",
    "    # Y_train 大概是这样的数据 [[0,1],[0,1],[1,0],[0,1],...]\n",
    "    # [0,1] 就是一张图片的标签，这里设置 [1,0] 代表 固体胶，[0,1] 代表西瓜霜\n",
    "    # 如果你有三类图片 Y_train 就因该设置为 (your_train_size,3)\n",
    "    \n",
    "    train_length = len(imglist_train_ZAZXCMAB) + len(imglist_train_ZUXJZPMFB)+ len(imglist_train_ZUXTSFB)+ len(imglist_train_ZUXWXSYFB)+ len(imglist_train_ZUXZYFB)+ len(imglist_train_ZXJXFB)\n",
    "    print(\"train_length\",train_length)\n",
    "    X_train = np.empty((train_length, 224, 224, 3))\n",
    "    Y_train = np.empty((train_length, 6))\n",
    "    count = 0\n",
    "    \n",
    "    for img_name in imglist_train_ZAZXCMAB:\n",
    "\n",
    "        img_path = train_path_ZAZXCMAB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((1,0,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_train_ZUXJZPMFB:\n",
    "\n",
    "        img_path = train_path_ZUXJZPMFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,1,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_train_ZUXTSFB:\n",
    "\n",
    "        img_path = train_path_ZUXTSFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,1,0,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZUXWXSYFB:\n",
    "\n",
    "        img_path = train_path_ZUXWXSYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,1,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZUXZYFB:\n",
    "\n",
    "        img_path = train_path_ZUXZYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,0,1,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZXJXFB:\n",
    "\n",
    "        img_path = train_path_ZXJXFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,0,0,1))\n",
    "        count+=1 \n",
    "        \n",
    "        \n",
    "    X_test = np.empty((len(imglist_test_ZAZXCMAB) + len(imglist_test_ZUXJZPMFB)+ len(imglist_test_ZUXTSFB)+ len(imglist_test_ZUXWXSYFB)+ len(imglist_test_ZUXZYFB)+ len(imglist_test_ZXJXFB), 224, 224, 3))\n",
    "    Y_test = np.empty((len(imglist_test_ZAZXCMAB) + len(imglist_test_ZUXJZPMFB)+ len(imglist_test_ZUXTSFB)+ len(imglist_test_ZUXWXSYFB)+ len(imglist_test_ZUXZYFB)+ len(imglist_test_ZXJXFB), 6))\n",
    "    count = 0\n",
    "    \n",
    "    for img_name in imglist_test_ZAZXCMAB:\n",
    "\n",
    "        img_path = test_path_ZAZXCMAB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((1,0,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_test_ZUXJZPMFB:\n",
    "\n",
    "        img_path = test_path_ZUXJZPMFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,1,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_test_ZUXTSFB:\n",
    "\n",
    "        img_path = test_path_ZUXTSFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,1,0,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZUXWXSYFB:\n",
    "\n",
    "        img_path = test_path_ZUXWXSYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,1,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZUXZYFB:\n",
    "\n",
    "        img_path = test_path_ZUXZYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,0,1,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZXJXFB:\n",
    "\n",
    "        img_path = test_path_ZXJXFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,0,0,1))\n",
    "        count+=1 \n",
    "        \n",
    "        \n",
    "    index = [i for i in range(len(X_train))]\n",
    "    random.shuffle(index)\n",
    "    X_train = X_train[index]\n",
    "    Y_train = Y_train[index]\n",
    "    \n",
    "    index = [i for i in range(len(X_test))]\n",
    "    random.shuffle(index)\n",
    "    X_test = X_test[index]    \n",
    "    Y_test = Y_test[index]\n",
    "\n",
    "    return X_train,Y_train,X_test,Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_length 168\n",
      "X_train shape :  (168, 224, 224, 3)\n",
      "Y_train shape :  (168, 6)\n",
      "X_test shape :  (72, 224, 224, 3)\n",
      "Y_test shape :  (72, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test = DataSet()\n",
    "print('X_train shape : ',X_train.shape)\n",
    "print('Y_train shape : ',Y_train.shape)\n",
    "print('X_test shape : ',X_test.shape)\n",
    "print('Y_test shape : ',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "#                  batch_size=32,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0, \n",
    "                 embeddings_layer_names=None, \n",
    "                 embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 168 samples, validate on 72 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "168/168 [==============================] - 401s 2s/sample - loss: 4.7654 - acc: 0.2083 - val_loss: 13.4317 - val_acc: 0.1667\n",
      "Epoch 2/5\n",
      "168/168 [==============================] - 398s 2s/sample - loss: 3.3433 - acc: 0.3155 - val_loss: 13.4317 - val_acc: 0.1667\n",
      "Epoch 3/5\n",
      "168/168 [==============================] - 390s 2s/sample - loss: 2.0682 - acc: 0.3869 - val_loss: 13.1256 - val_acc: 0.1667\n",
      "Epoch 4/5\n",
      "168/168 [==============================] - 443s 3s/sample - loss: 1.6530 - acc: 0.4107 - val_loss: 3.3336 - val_acc: 0.1944\n",
      "Epoch 5/5\n",
      "168/168 [==============================] - 453s 3s/sample - loss: 1.5272 - acc: 0.5000 - val_loss: 3.3866 - val_acc: 0.2639\n"
     ]
    }
   ],
   "source": [
    "# # model\n",
    "\n",
    "\n",
    "model = ResNet50(\n",
    "    weights=None,\n",
    "    classes=6\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # train\n",
    "\n",
    "hist = model.fit(X_train, Y_train, \n",
    "                 epochs=5, \n",
    "                 batch_size=6, \n",
    "                 validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个绘图窗口\n",
    "plt.figure()\n",
    " \n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc') # 'bo'为画蓝色圆点，不连线\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend() # 绘制图例，默认在右上角\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # evaluate\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# # save\n",
    "\n",
    "\n",
    "model.save('my_resnet_model.h5')\n",
    "\n",
    "# # restore\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('my_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
