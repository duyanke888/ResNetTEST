{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSet():\n",
    "    \n",
    "    train_path_ZAZXCMAB ='./mynn/train/ZAZXCMAB/'\n",
    "    train_path_ZUXJZPMFB = './mynn/train/ZUXJZPMFB/'\n",
    "    train_path_ZUXTSFB = './mynn/train/ZUXTSFB/'\n",
    "    train_path_ZUXWXSYFB = './mynn/train/ZUXWXSYFB/'\n",
    "    train_path_ZUXZYFB = './mynn/train/ZUXZYFB/'\n",
    "    train_path_ZXJXFB = './mynn/train/ZXJXFB/'\n",
    "    \n",
    "    test_path_ZAZXCMAB ='./mynn/test/ZAZXCMAB/'\n",
    "    test_path_ZUXJZPMFB = './mynn/test/ZUXJZPMFB/'\n",
    "    test_path_ZUXTSFB = './mynn/test/ZUXTSFB/'\n",
    "    test_path_ZUXWXSYFB = './mynn/test/ZUXWXSYFB/'\n",
    "    test_path_ZUXZYFB = './mynn/test/ZUXZYFB/'\n",
    "    test_path_ZXJXFB = './mynn/test/ZXJXFB/'\n",
    "    \n",
    "    imglist_train_ZAZXCMAB = os.listdir(train_path_ZAZXCMAB)\n",
    "    imglist_train_ZUXJZPMFB = os.listdir(train_path_ZUXJZPMFB)\n",
    "    imglist_train_ZUXTSFB = os.listdir(train_path_ZUXTSFB)\n",
    "    imglist_train_ZUXWXSYFB = os.listdir(train_path_ZUXWXSYFB)\n",
    "    imglist_train_ZUXZYFB = os.listdir(train_path_ZUXZYFB)\n",
    "    imglist_train_ZXJXFB = os.listdir(train_path_ZXJXFB)\n",
    "    \n",
    "    imglist_test_ZAZXCMAB = os.listdir(test_path_ZAZXCMAB)\n",
    "    imglist_test_ZUXJZPMFB = os.listdir(test_path_ZUXJZPMFB)\n",
    "    imglist_test_ZUXTSFB = os.listdir(test_path_ZUXTSFB)\n",
    "    imglist_test_ZUXWXSYFB = os.listdir(test_path_ZUXWXSYFB)\n",
    "    imglist_test_ZUXZYFB = os.listdir(test_path_ZUXZYFB)\n",
    "    imglist_test_ZXJXFB = os.listdir(test_path_ZXJXFB)\n",
    "    \n",
    "    # 这里定义两个 numpy 对象，X_train 和 Y_train\n",
    "    \n",
    "    # X_train 对象用来存放训练集的图片。每张图片都需要转换成 numpy 向量形式\n",
    "    # X_train 的 shape 是 (360，224，224，3) \n",
    "    # 360 是训练集中图片的数量\n",
    "    # 因为 resnet 要求输入的图片尺寸是 (224,224) , 所以要设置成相同大小（也可以设置成其它大小，参看 keras 的文档）\n",
    "    # 3 是图片的通道数（rgb）\n",
    "    \n",
    "    # Y_train 用来存放训练集中每张图片对应的标签\n",
    "    # Y_train 的 shape 是 （360，2）\n",
    "    # 360 是训练集中图片的数量（训练集中固体胶和西瓜霜图片数量之和）\n",
    "    # 因为一共有两种图片，所以第二个维度设置为 2\n",
    "    # Y_train 大概是这样的数据 [[0,1],[0,1],[1,0],[0,1],...]\n",
    "    # [0,1] 就是一张图片的标签，这里设置 [1,0] 代表 固体胶，[0,1] 代表西瓜霜\n",
    "    # 如果你有三类图片 Y_train 就因该设置为 (your_train_size,3)\n",
    "    \n",
    "    train_length = len(imglist_train_ZAZXCMAB) + len(imglist_train_ZUXJZPMFB)+ len(imglist_train_ZUXTSFB)+ len(imglist_train_ZUXWXSYFB)+ len(imglist_train_ZUXZYFB)+ len(imglist_train_ZXJXFB)\n",
    "    print(\"train_length\",train_length)\n",
    "    X_train = np.empty((train_length, 224, 224, 3))\n",
    "    Y_train = np.empty((train_length, 6))\n",
    "    count = 0\n",
    "    \n",
    "    for img_name in imglist_train_ZAZXCMAB:\n",
    "\n",
    "        img_path = train_path_ZAZXCMAB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((1,0,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_train_ZUXJZPMFB:\n",
    "\n",
    "        img_path = train_path_ZUXJZPMFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,1,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_train_ZUXTSFB:\n",
    "\n",
    "        img_path = train_path_ZUXTSFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,1,0,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZUXWXSYFB:\n",
    "\n",
    "        img_path = train_path_ZUXWXSYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,1,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZUXZYFB:\n",
    "\n",
    "        img_path = train_path_ZUXZYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,0,1,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_train_ZXJXFB:\n",
    "\n",
    "        img_path = train_path_ZXJXFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_train[count] = img\n",
    "        Y_train[count] = np.array((0,0,0,0,0,1))\n",
    "        count+=1 \n",
    "        \n",
    "        \n",
    "    X_test = np.empty((len(imglist_test_ZAZXCMAB) + len(imglist_test_ZUXJZPMFB)+ len(imglist_test_ZUXTSFB)+ len(imglist_test_ZUXWXSYFB)+ len(imglist_test_ZUXZYFB)+ len(imglist_test_ZXJXFB), 224, 224, 3))\n",
    "    Y_test = np.empty((len(imglist_test_ZAZXCMAB) + len(imglist_test_ZUXJZPMFB)+ len(imglist_test_ZUXTSFB)+ len(imglist_test_ZUXWXSYFB)+ len(imglist_test_ZUXZYFB)+ len(imglist_test_ZXJXFB), 6))\n",
    "    count = 0\n",
    "    \n",
    "    for img_name in imglist_test_ZAZXCMAB:\n",
    "\n",
    "        img_path = test_path_ZAZXCMAB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((1,0,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_test_ZUXJZPMFB:\n",
    "\n",
    "        img_path = test_path_ZUXJZPMFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,1,0,0,0,0))\n",
    "        count+=1\n",
    "    \n",
    "    for img_name in imglist_test_ZUXTSFB:\n",
    "\n",
    "        img_path = test_path_ZUXTSFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,1,0,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZUXWXSYFB:\n",
    "\n",
    "        img_path = test_path_ZUXWXSYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,1,0,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZUXZYFB:\n",
    "\n",
    "        img_path = test_path_ZUXZYFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,0,1,0))\n",
    "        count+=1\n",
    "        \n",
    "    for img_name in imglist_test_ZXJXFB:\n",
    "\n",
    "        img_path = test_path_ZXJXFB + img_name\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "\n",
    "        X_test[count] = img\n",
    "        Y_test[count] = np.array((0,0,0,0,0,1))\n",
    "        count+=1 \n",
    "        \n",
    "        \n",
    "    index = [i for i in range(len(X_train))]\n",
    "    random.shuffle(index)\n",
    "    X_train = X_train[index]\n",
    "    Y_train = Y_train[index]\n",
    "    \n",
    "    index = [i for i in range(len(X_test))]\n",
    "    random.shuffle(index)\n",
    "    X_test = X_test[index]    \n",
    "    Y_test = Y_test[index]\n",
    "\n",
    "    return X_train,Y_train,X_test,Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_length 779\n",
      "X_train shape :  (779, 224, 224, 3)\n",
      "Y_train shape :  (779, 6)\n",
      "X_test shape :  (167, 224, 224, 3)\n",
      "Y_test shape :  (167, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_test,Y_test = DataSet()\n",
    "print('X_train shape : ',X_train.shape)\n",
    "print('Y_train shape : ',Y_train.shape)\n",
    "print('X_test shape : ',X_test.shape)\n",
    "print('Y_test shape : ',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 779 samples\n",
      "Epoch 1/10\n",
      "779/779 [==============================] - 127s 163ms/sample - loss: 2.4838 - accuracy: 0.2413\n",
      "Epoch 2/10\n",
      "779/779 [==============================] - 89s 114ms/sample - loss: 1.7305 - accuracy: 0.2850\n",
      "Epoch 3/10\n",
      "779/779 [==============================] - 89s 114ms/sample - loss: 1.5867 - accuracy: 0.2965\n",
      "Epoch 4/10\n",
      "779/779 [==============================] - 89s 114ms/sample - loss: 1.5393 - accuracy: 0.3543\n",
      "Epoch 5/10\n",
      "779/779 [==============================] - 88s 113ms/sample - loss: 1.5166 - accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "114/779 [===>..........................] - ETA: 1:15 - loss: 1.3620 - accuracy: 0.3947"
     ]
    }
   ],
   "source": [
    "# # model\n",
    "\n",
    "\n",
    "model = ResNet50(\n",
    "    weights=None,\n",
    "    classes=6\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # train\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=10, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个绘图窗口\n",
    "plt.figure()\n",
    " \n",
    "acc = hist.history['accuracy']\n",
    "# val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "# val_loss = hist.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc') # 'bo'为画蓝色圆点，不连线\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend() # 绘制图例，默认在右上角\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # evaluate\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# # save\n",
    "\n",
    "\n",
    "model.save('my_resnet_model.h5')\n",
    "\n",
    "# # restore\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('my_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
